

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Retrieval Augmented Generation &#8212; Kellogg Research Support Open Source LLM Cookbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'retrieval';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Fine-Tuning" href="fine-tuning.html" />
    <link rel="prev" title="Example Use Case: 10K Processing" href="use_case.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="welcome.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Kellogg Research Support Open Source LLM Cookbook - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Kellogg Research Support Open Source LLM Cookbook - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="welcome.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Open Source Large Language Models (LLMs)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Running Open Source LLMs on KLC</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="slurm_gpu_usage.html">Using GPUs at Northwestern</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformers.html">Using Transformers to run LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="llama-cpp.html">Using Llama-cpp-python to run LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="use_case.html">Example Use Case: 10K Processing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Techniques</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Retrieval Augmented Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="fine-tuning.html">Fine-Tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="vision.html">Image Processing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Summary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="takeaways.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/rs-kellogg/krs-openllm-cookbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/rs-kellogg/krs-openllm-cookbook/issues/new?title=Issue%20on%20page%20%2Fretrieval.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/retrieval.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Retrieval Augmented Generation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-sample-uses-cases-font"><font color="purple">Sample Uses Cases</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-how-it-works-font"><font color="purple">How it Works</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-example-retrieving-information-non-existent-in-training-font"><font color="purple">Example: Retrieving Information Non-existent in Training</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-sample-scripts-font"><font color="purple">Sample scripts</font></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="retrieval-augmented-generation">
<h1>Retrieval Augmented Generation<a class="headerlink" href="#retrieval-augmented-generation" title="Permalink to this heading">#</a></h1>
<p><font color='purple'>Retrieval Augmented Generation (RAG)</font> is a powerful paradigm in natural language processing that combines the strengths of information retrieval and language generation. This approach involves retrieving relevant information from a large dataset and using that information to enhance the generation of accurate text.</p>
<p>The phrase <font color='purple'>Retrieval Augmented Generation</font> comes from a recent <a class="reference external" href="https://research.facebook.com/publications/retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks/">paper by Lewis et al. from Facebook AI</a>. The idea is to use a pre-trained language model (LM) to generate text, but to use a separate retrieval system to find relevant documents to condition the LM on.</p>
<section id="font-color-purple-sample-uses-cases-font">
<h2><font color='purple'>Sample Uses Cases</font><a class="headerlink" href="#font-color-purple-sample-uses-cases-font" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Question Answering Systems or Conversational Agents</strong>:<br />
Retrieve information from vast knowledge bases, such as multiple pdf or csv files, and incorporate into response.</p></li>
<li><p><strong>Context Creation</strong>:<br />
Enhance the generation of informative text by pulling in relevant details from a wide range of sources.</p></li>
<li><p><strong>Code Generation</strong>:<br />
Assist in generating code snippets by retrieving information from programming knowledge bases.</p></li>
<li><p><strong>Prevent Hallucinations</strong>:<br />
Bring in external knowledge to check whether a GPT response is a hallucination.</p></li>
</ul>
</section>
<section id="font-color-purple-how-it-works-font">
<h2><font color='purple'>How it Works</font><a class="headerlink" href="#font-color-purple-how-it-works-font" title="Permalink to this heading">#</a></h2>
<p>From start to finish, the RAG relies on 5 steps:
<img alt="RAG steps" src="_images/rag.png" /></p>
<p><strong>1. Load</strong><br />
Load documents from different source files (<em>url, csv, pdf, txt</em>) in diverse locations (s3 storage, public sites, etc.)</p>
<p><strong>2. Transform</strong><br />
Prepare larger documents for retrieval by creating splits or chunks the data.</p>
<p><strong>3. Embed</strong><br />
Create embeddings for documents to capture the semantic meaning of the text. This later enables models to efficiently find other pieces of text that are similar.</p>
<p><strong>4. Store</strong><br />
Vector stores support efficient storage and search of document embeddings.</p>
<p><strong>5. Retrieve</strong><br />
Relevant information is retrieved to produce more informed and context-aware responses.</p>
<p>During runtime, this blending of retrieval and generation enhances the richness and relevance of the generated content.
<img alt="RAG runtime" src="_images/basic_rag.png" /></p>
<p><em>Taken from: <span class="xref myst">https://docs.llamaindex.ai/en/stable/_static/getting_started/basic_rag.png</span></em></p>
</section>
<section id="font-color-purple-example-retrieving-information-non-existent-in-training-font">
<h2><font color='purple'>Example: Retrieving Information Non-existent in Training</font><a class="headerlink" href="#font-color-purple-example-retrieving-information-non-existent-in-training-font" title="Permalink to this heading">#</a></h2>
<p>One way to use RAG is to feed the LLM with up-to-date information.<br />
The Llama 2 was trained between January 2023 and July 2023. The Mistral 7B model was released in September 2023. Let’s ask LLama2 a question about the Mistral 7B model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the query through Llama2 7B chat model with test_llama2.py  </span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;[INST]How can I use tranformers to call the Mistral 7B instruct model?[/INST]&quot;</span>
</pre></div>
</div>
<p><strong>Output:</strong></p>
<blockquote>
<div><p>[INST]How can I use tranformers to call the Mistral 7B instruct model?[/INST]<br />
To use Transformers to call the Mistral 7B instruct model, you can follow these general steps:</p>
<ol class="arabic simple">
<li><p>Install the necessary dependencies: You will need to install the <code class="docutils literal notranslate"><span class="pre">transformers</span></code> library and any other dependencies required by the model you want to use.</p></li>
<li><p>Load the model: You can use the <code class="docutils literal notranslate"><span class="pre">transformers.BertModel</span></code> class to load the Mistral 7B model. For example:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">BertModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;mistral-7b-base-uncased&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Prepare the input: You will need to prepare the input for the model. This can involve tokenizing the text, padding it to the appropriate length, and converting it to a format that the model can understand.</p></li>
<li><p>Call the model: You can use the <code class="docutils literal notranslate"><span class="pre">model.predict()</span></code> method to call the model on a given input. For example:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_text</span> <span class="o">=</span> <span class="s1">&#39;This is a sample input text.&#39;</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Interpret the output: Once you have called the model, you can interpret the output in a way that makes sense for your use case. For example, you could use the output to generate a summary of the input text, or to perform some other task that requires understanding natural language.</p></li>
</ol>
<p>Note that the specific details of how to use the Mistral 7B model will depend on the implementation of the model and the library you are using. You may need to consult the documentation</p>
</div></blockquote>
<p>The huggingface page for Mistral 7B Instruct model can be found <a class="reference external" href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">here</a>.<br />
We can use RAG to feed up-to-date information. The code below will take the contents of a webpage and follow the 5 steps outlined above to retrieve the relevant information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load libraries</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">llama_index.core</span> <span class="kn">import</span> <span class="n">VectorStoreIndex</span><span class="p">,</span> <span class="n">SimpleDirectoryReader</span>
<span class="kn">from</span> <span class="nn">llama_index.core</span> <span class="kn">import</span> <span class="n">StorageContext</span><span class="p">,</span> <span class="n">load_index_from_storage</span>
<span class="kn">from</span> <span class="nn">llama_index.core.node_parser</span> <span class="kn">import</span> <span class="n">SentenceSplitter</span>
<span class="kn">from</span> <span class="nn">llama_index.llms.huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceLLM</span>
<span class="kn">from</span> <span class="nn">llama_index.embeddings.huggingface</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbedding</span>
<span class="kn">from</span> <span class="nn">llama_index.vector_stores.faiss</span> <span class="kn">import</span> <span class="n">FaissVectorStore</span>
<span class="kn">import</span> <span class="nn">faiss</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1"># Save text from the url link</span>
<span class="k">def</span> <span class="nf">prep_text</span><span class="p">(</span><span class="n">workdir</span><span class="p">,</span> <span class="n">url_link</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url_link</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="n">webpage_content</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">webpage_content</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">linesep</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">webpage_content</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span> <span class="k">if</span> <span class="n">s</span><span class="p">])</span>

    <span class="n">data_path</span> <span class="o">=</span> <span class="n">workdir</span> <span class="o">/</span> <span class="s2">&quot;LlamaIndex_data&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">data_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="n">data_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>

    <span class="n">txt_file</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">/</span> <span class="s2">&quot;webpage_content.txt&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">txt_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">webpage_content</span><span class="p">)</span>

<span class="c1"># Perform RAG using LlamaIndex</span>
<span class="k">def</span> <span class="nf">process_llamaindex</span><span class="p">(</span><span class="n">workdir</span><span class="p">,</span> <span class="n">embedding_name</span><span class="p">,</span> <span class="n">embed_d</span><span class="p">,</span> <span class="n">llm_model</span><span class="p">,</span> <span class="n">query</span><span class="p">):</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">))</span>

    <span class="n">embedding_chunk_size</span> <span class="o">=</span> <span class="mi">1024</span>
    <span class="n">embed_model</span> <span class="o">=</span> <span class="n">HuggingFaceEmbedding</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">embedding_name</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="n">HuggingFaceLLM</span><span class="p">(</span>
        <span class="n">context_window</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">tokenizer_name</span><span class="o">=</span><span class="n">llm_model</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="n">llm_model</span><span class="p">,</span>
        <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">PERSIST_DIR</span> <span class="o">=</span> <span class="n">workdir</span> <span class="o">/</span> <span class="s2">&quot;LlamaIndex_storage_faiss&quot;</span>
    <span class="n">data_path</span> <span class="o">=</span> <span class="n">workdir</span> <span class="o">/</span> <span class="s2">&quot;LlamaIndex_data&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">PERSIST_DIR</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Processing data ... &quot;</span><span class="p">)</span>

        <span class="c1">##############################</span>
        <span class="c1"># 1. Load the documents</span>
        <span class="c1">##############################</span>
        <span class="n">documents</span> <span class="o">=</span> <span class="n">SimpleDirectoryReader</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

        <span class="c1"># Set up FAISS vector store</span>
        <span class="n">faiss_index</span> <span class="o">=</span> <span class="n">faiss</span><span class="o">.</span><span class="n">IndexFlatL2</span><span class="p">(</span><span class="n">embed_d</span><span class="p">)</span>
        <span class="n">vector_store</span> <span class="o">=</span> <span class="n">FaissVectorStore</span><span class="p">(</span><span class="n">faiss_index</span><span class="o">=</span><span class="n">faiss_index</span><span class="p">)</span>
        <span class="n">storage_context</span> <span class="o">=</span> <span class="n">StorageContext</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span><span class="n">vector_store</span><span class="o">=</span><span class="n">vector_store</span><span class="p">)</span>

        <span class="n">index</span> <span class="o">=</span> <span class="n">VectorStoreIndex</span><span class="o">.</span><span class="n">from_documents</span><span class="p">(</span>
            <span class="n">documents</span><span class="p">,</span> 
            <span class="c1">##############################</span>
            <span class="c1"># 2. Transform</span>
            <span class="c1">##############################</span>
            <span class="n">transformations</span><span class="o">=</span><span class="p">[</span><span class="n">SentenceSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="n">embedding_chunk_size</span><span class="p">)],</span>
            <span class="c1">##############################</span>
            <span class="c1"># 3. Embed</span>
            <span class="c1">##############################</span>
            <span class="n">embed_model</span><span class="o">=</span><span class="n">embed_model</span><span class="p">,</span> 
            <span class="c1">##############################</span>
            <span class="c1"># 4. Store</span>
            <span class="c1">##############################</span>
            <span class="n">storage_context</span><span class="o">=</span><span class="n">storage_context</span>
        <span class="p">)</span>
        <span class="n">index</span><span class="o">.</span><span class="n">storage_context</span><span class="o">.</span><span class="n">persist</span><span class="p">(</span><span class="n">persist_dir</span><span class="o">=</span><span class="n">PERSIST_DIR</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Finish saving vector store data ... &quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Storage exists. Loading data ...&quot;</span><span class="p">)</span>

        <span class="n">vector_store</span> <span class="o">=</span> <span class="n">FaissVectorStore</span><span class="o">.</span><span class="n">from_persist_dir</span><span class="p">(</span><span class="n">PERSIST_DIR</span><span class="p">)</span>
        <span class="n">storage_context</span> <span class="o">=</span> <span class="n">StorageContext</span><span class="o">.</span><span class="n">from_defaults</span><span class="p">(</span>
            <span class="n">persist_dir</span><span class="o">=</span><span class="n">PERSIST_DIR</span><span class="p">,</span>
            <span class="n">vector_store</span><span class="o">=</span><span class="n">vector_store</span><span class="p">,</span> 
        <span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">load_index_from_storage</span><span class="p">(</span>
            <span class="n">transformations</span><span class="o">=</span><span class="p">[</span><span class="n">SentenceSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="n">embedding_chunk_size</span><span class="p">)],</span>
            <span class="n">embed_model</span><span class="o">=</span><span class="n">embed_model</span><span class="p">,</span> 
            <span class="n">storage_context</span><span class="o">=</span><span class="n">storage_context</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Finish loading ...&quot;</span><span class="p">)</span>

    <span class="c1">##############################</span>
    <span class="c1"># 5. Retrieve</span>
    <span class="c1">##############################</span>
    <span class="n">query_engine</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">as_query_engine</span><span class="p">(</span><span class="n">llm</span> <span class="o">=</span> <span class="n">llm</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected LLM: </span><span class="si">{</span><span class="n">llm_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">query_engine</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Query: </span><span class="si">{</span><span class="n">query</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Response: &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>


<span class="c1"># Replace your_file_directory with your project directory string</span>
<span class="n">file_dir</span> <span class="o">=</span> <span class="n">your_file_directory</span>
<span class="n">workdir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">file_dir</span><span class="p">)</span>
<span class="n">url_link</span> <span class="o">=</span> <span class="s2">&quot;https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2&quot;</span>
<span class="n">prep_text</span><span class="p">(</span><span class="n">workdir</span><span class="p">,</span> <span class="n">url_link</span><span class="p">)</span>


<span class="c1"># Settings for embedding model</span>
<span class="c1"># embedding_name = &quot;intfloat/multilingual-e5-large-instruct&quot;</span>
<span class="n">embedding_name</span> <span class="o">=</span> <span class="s2">&quot;/kellogg/data/llm_models_opensource/e5_infloat/models--intfloat--multilingual-e5-large-instruct/snapshots/baa7be480a7de1539afce709c8f13f833a510e0a&quot;</span>
<span class="n">embed_d</span> <span class="o">=</span> <span class="mi">1024</span> <span class="c1"># embedding dimension</span>

<span class="c1"># Settings for LLM</span>
<span class="n">LLAMA2_7B_CHAT</span> <span class="o">=</span> <span class="s2">&quot;/kellogg/data/llm_models_opensource/llama2_meta_huggingface/models--meta-llama--Llama-2-7b-chat-hf/snapshots/92011f62d7604e261f748ec0cfe6329f31193e33&quot;</span>
<span class="c1"># LLAMA2_13B_CHAT = &quot;/kellogg/data/llm_models_opensource/llama2_meta_huggingface/models--meta-llama--Llama-2-13b-chat-hf/snapshots/29655417e51232f4f2b9b5d3e1418e5a9b04e80e&quot;</span>
<span class="n">llm_model</span> <span class="o">=</span> <span class="n">LLAMA2_7B_CHAT</span>
<span class="c1"># llm_model = LLAMA2_13B_CHAT</span>

<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;[INST]How can I use tranformers to call the Mistral 7B instruct model?[/INST]&quot;</span>

<span class="n">process_llamaindex</span><span class="p">(</span><span class="n">workdir</span><span class="p">,</span> <span class="n">embedding_name</span><span class="p">,</span> <span class="n">embed_d</span><span class="p">,</span> <span class="n">llm_model</span><span class="p">,</span> <span class="n">query</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Output:</strong></p>
<blockquote>
<div><p>Selected LLM: /kellogg/data/llm_models_opensource/llama2_meta_huggingface/models–meta-llama–Llama-2-7b-chat-hf/snapshots/92011f62d7604e261f748ec0cfe6329f31193e33</p>
<p>Batches:   0%|          | 0/1 [00:00&lt;?, ?it/s]<br />
Batches: 100%|██████████| 1/1 [00:00&lt;00:00, 63.51it/s]</p>
<p>Query: [INST]How can I use tranformers to call the Mistral 7B instruct model?[/INST]<br />
Response:</p>
<p>To use transformers to call the Mistral 7B Instruct model, you can follow these steps:</p>
<ol class="arabic simple">
<li><p>Install the transformers library by running <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">transformers</span></code> in your terminal.</p></li>
<li><p>Import the AutoModelForCausalLM and AutoTokenizer classes from the transformers library:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>  
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Load the Mistral 7B Instruct model using the <code class="docutils literal notranslate"><span class="pre">from_pretrained</span></code> method:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;mistralai/Mistral-7B-Instruct-v0.2&quot;</span><span class="p">)</span>  
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Use the <code class="docutils literal notranslate"><span class="pre">apply_chat_template</span></code> method to apply the instruction format to a given set of messages:</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>  
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;What is your favourite condiment?&quot;</span><span class="p">},</span>  
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Well, I&#39;m quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I&#39;m cooking up in the kitchen!&quot;</span><span class="p">},</span>  
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;Do you have mayonnaise recipes?&quot;</span><span class="p">}</span>  
<span class="p">]</span>  
  
<span class="n">encodeds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>  
<span class="n">model_inputs</span> <span class="o">=</span> <span class="n">encodeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>  
<span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  
<span class="n">decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">decoded</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Fine-tune the model by adjusting the hyperparameters or adding additional data to improve its performance.</p></li>
</ol>
<p>Note: The <code class="docutils literal notranslate"><span class="pre">mistralai</span></code> name is a placeholder for the actual model name, which you can replace with the name of your own model. Also, make sure to install the transformers library by running <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">transformers</span></code> in your terminal.</p>
</div></blockquote>
</section>
<section id="font-color-purple-sample-scripts-font">
<h2><font color='purple'>Sample scripts</font><a class="headerlink" href="#font-color-purple-sample-scripts-font" title="Permalink to this heading">#</a></h2>
<p>Sample scripts can be found at the <a class="reference external" href="https://github.com/rs-kellogg/krs-openllm-cookbook/tree/main/scripts/rag">scripts/rag</a> folder of our github repo.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="use_case.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Example Use Case: 10K Processing</p>
      </div>
    </a>
    <a class="right-next"
       href="fine-tuning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fine-Tuning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-sample-uses-cases-font"><font color="purple">Sample Uses Cases</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-how-it-works-font"><font color="purple">How it Works</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-example-retrieving-information-non-existent-in-training-font"><font color="purple">Example: Retrieving Information Non-existent in Training</font></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#font-color-purple-sample-scripts-font"><font color="purple">Sample scripts</font></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kellogg Research Support
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>