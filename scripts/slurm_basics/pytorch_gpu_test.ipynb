{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6912db-bc7a-476b-b09d-05ce47fb301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cee95f-3678-4f59-bf94-d445c8870cad",
   "metadata": {},
   "source": [
    "# Check for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554060db-e50f-4d5c-a5b5-a957930fe186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Number of GPUs available: 1\n",
      "GPU: NVIDIA A100-PCIE-40GB\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed96a915-3fce-4f42-8fa3-885978935c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "622a6a13-a6cc-436f-8d04-cb7860fec9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3412, -2.9746,  1.6327,  ...,  1.7762,  1.1176, -0.6660],\n",
      "        [-0.7098, -1.0529,  0.7931,  ...,  1.2098, -0.3568, -0.5596],\n",
      "        [ 3.3406, -1.2258, -2.7458,  ..., -0.6209, -0.3127,  1.0155],\n",
      "        ...,\n",
      "        [-0.8189,  2.3436,  2.2477,  ...,  1.2224, -1.5397,  0.0579],\n",
      "        [-0.2297, -2.2453, -0.7732,  ..., -0.3020,  1.9078,  1.2613],\n",
      "        [-0.6079,  0.5231, -0.5131,  ..., -0.5740,  3.3171,  1.2996]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors\n",
    "tensor1 = torch.randn(1000, 1000, device=device)\n",
    "tensor2 = torch.randn(1000, 1000, device=device)\n",
    "\n",
    "# Add the two tensors, the operation will be performed on the GPU if available\n",
    "result = tensor1 + tensor2\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2c8505-af19-443d-821c-cc12f04e2149",
   "metadata": {},
   "source": [
    "# Compare speed of CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad551edd-74af-416d-8bd1-1be7acec38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random matrix\n",
    "matrix_size = 10000\n",
    "x = torch.randn(matrix_size, matrix_size, device=\"cpu\")\n",
    "y = torch.randn(matrix_size, matrix_size, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59acfb6-5279-4be5-8905-82ed3113aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 ms ± 757 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "result = torch.div(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da40768-9912-4a24-a5c4-f54fcf473d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gpu = x.to(\"cuda\")\n",
    "y_gpu = y.to(\"cuda\")\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2514b1d8-dd12-4d28-ae96-4ec6c5cc1b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 30.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "53.4 µs ± 101 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "result_gpu = torch.div(x_gpu,y_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d3a23-a24e-463c-bb98-0ef86baf113a",
   "metadata": {},
   "source": [
    "### The GPU is 3 orders of magnitude faster on this operation!\n",
    "\n",
    "![image](./time-scale.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab9234-3227-4aae-8e21-779fe8830413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Test Env",
   "language": "python",
   "name": "llm-test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
