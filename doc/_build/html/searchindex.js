Search.setIndex({"docnames": ["fine-tuning", "introduction", "llama-cpp", "retrieval", "slurm_gpu_usage", "survey", "takeaways", "transformers", "use_case", "vision", "welcome"], "filenames": ["fine-tuning.ipynb", "introduction.ipynb", "llama-cpp.ipynb", "retrieval.ipynb", "slurm_gpu_usage.ipynb", "survey.ipynb", "takeaways.ipynb", "transformers.ipynb", "use_case.ipynb", "vision.ipynb", "welcome.ipynb"], "titles": ["Fine-Tuning", "Introduction", "Using Llama_cpp_python to run LLMs", "Retrieval Augmented Generation", "Using GPUs at Northwestern", "LLMs for Survey", "Summary and Takeaways", "Using Transformers to run LLMs", "Example Use Case", "Process Images with bakllava", "Welcome"], "terms": {"take": [0, 1, 2, 3, 4, 9], "larg": [0, 1, 2, 3, 4, 7, 10], "languag": [0, 3, 10], "beyond": 0, "basic": 0, "prompt": [0, 1, 2, 7, 9], "It": [0, 3], "allow": [0, 2, 4], "you": [0, 1, 2, 3, 4, 7, 9, 10], "train": [0, 1, 2, 9], "specif": [0, 2, 3], "tailor": 0, "your": [0, 1, 2, 3, 4, 7, 9], "desir": 0, "task": [0, 1, 2, 3, 4], "lead": [0, 2], "sever": 0, "advantag": [0, 1], "superior": 0, "result": [0, 1, 2, 4], "compar": [0, 2], "can": [0, 1, 2, 3, 4, 7, 9], "deliv": 0, "higher": [0, 2], "qualiti": 0, "output": [0, 1, 2, 3, 4, 7, 9], "becaus": 0, "i": [0, 1, 3, 4, 7, 9, 10], "updat": 0, "its": [0, 1, 2, 3, 7], "weight": [0, 1, 2, 7], "base": [0, 1, 2, 3, 4], "off": [0, 2], "supervis": 0, "exampl": [0, 2, 4], "provid": [0, 1, 2, 4, 9], "produc": [0, 3], "special": [0, 2, 4, 9], "need": [0, 1, 2, 3, 7, 10], "effici": [0, 2, 3, 4], "The": [0, 1, 2, 3, 4, 7, 9, 10], "typic": 0, "requir": [0, 2, 3, 4], "shorter": 0, "get": [0, 2, 3, 4, 9], "behavior": 0, "ar": [0, 1, 2, 3, 4, 9], "alreadi": 0, "us": [0, 9], "case": [0, 2, 4], "thi": [0, 1, 2, 3, 9, 10], "save": [0, 2, 3, 4, 9], "token": [0, 2, 3, 7, 9], "usag": [0, 2], "reduc": [0, 1, 2, 7], "latenc": 0, "request": [0, 3, 4, 9], "excel": 0, "style": 0, "tone": [0, 2], "format": [0, 2, 3], "consist": [0, 2], "enhanc": [0, 3], "reliabl": 0, "achiev": [0, 1], "handl": [0, 4], "complex": [0, 2], "instruct": [0, 2, 3, 7], "better": [0, 1, 2, 4, 9], "tackl": [0, 1], "edg": 0, "effect": [0, 10], "new": [0, 1, 7, 9], "skill": [0, 10], "empow": 0, "master": 0, "complet": [0, 1, 4], "difficult": 0, "articul": 0, "through": [0, 1, 2, 3, 4], "simpl": 0, "befor": [0, 2], "delv": 0, "mechan": 0, "note": [0, 2, 3], "might": [0, 2, 4], "alwai": [0, 1], "best": [0, 1], "solut": 0, "here": [0, 2, 3, 4, 7, 9], "": [0, 2, 3, 4, 7, 9], "breakdown": 0, "when": [0, 2, 4], "appli": [0, 2, 3], "engin": [0, 2], "rag": [0, 2, 3], "good": [0, 1, 3], "simpler": [0, 2], "without": 0, "extens": 0, "data": [0, 1, 2, 3, 7, 9], "break": [0, 2], "down": [0, 2], "smaller": [0, 4], "sequenti": [0, 4], "follow": [0, 2, 3, 7, 9], "chain": 0, "retriev": [0, 2], "augment": 0, "gener": [0, 2, 4, 7, 9], "situat": 0, "relev": [0, 3], "document": [0, 1, 3], "databas": 0, "factual": [0, 2], "accuraci": [0, 1, 2], "where": [0, 4, 7], "context": [0, 2, 3], "benefici": 0, "access": [0, 1, 2], "inform": [0, 1, 2], "newer": 0, "than": [0, 1, 2, 4], "cutoff": [0, 1], "date": [0, 1, 3], "particular": 0, "from": [0, 1, 2, 3, 4, 7, 9], "express": 0, "our": [0, 1, 2, 3, 4, 9], "advic": 0, "experi": [0, 9], "craft": [0, 1], "attempt": 0, "low": 0, "cost": [0, 1, 7], "doe": [0, 2], "ani": [0, 3], "program": [0, 3, 4], "differ": [0, 1, 2, 3], "few": 0, "shot": 0, "learn": [0, 7], "thought": 0, "more": [0, 2, 3, 4], "effort": 0, "collect": [0, 1], "some": [0, 1, 2, 3, 4, 7, 9], "work": [0, 2, 10], "extra": 0, "gpu": [0, 1, 2, 7, 9], "resourc": [0, 1, 2], "storag": [0, 2, 3], "In": [0, 2, 4], "workshop": [0, 1, 4], "we": [0, 1, 2, 3, 4, 9], "ll": [0, 2, 4], "demonstr": [0, 2, 4, 8], "how": [0, 1, 2, 4, 9], "mistral": [0, 3], "especi": [0, 4], "apt": 0, "perform": [0, 1, 3, 4], "classif": 0, "first": 0, "should": [0, 1], "properli": 0, "out": [0, 2, 4, 7], "box": 0, "code": [0, 1, 2, 3, 9], "below": [0, 2, 3, 4], "quantiz": [0, 1, 7], "transform": [0, 3, 8], "text": [0, 2, 3, 7], "ag": [0, 9], "hug": [0, 1, 2, 7], "face": [0, 1, 2, 7], "http": [0, 2, 3, 7, 9], "huggingfac": [0, 2, 3, 7, 9], "co": [0, 2, 3, 7, 9], "ag_new": 0, "ask": [0, 3, 9], "classifi": 0, "1": [0, 2, 3, 4, 7, 9], "4": [0, 1, 2, 3, 7, 9], "categori": 0, "0": [0, 2, 3, 4, 7, 9], "world": 0, "sport": 0, "2": [0, 2, 3, 4, 7, 9], "busi": [0, 7], "3": [0, 2, 3, 7, 9], "scienc": 0, "technologi": 0, "place": [0, 2], "syntax": [0, 2], "find": [0, 2, 3], "query_initi": 0, "py": [0, 2, 3, 7, 9], "script": [0, 2, 9], "fine_tun": 0, "folder": [0, 3], "github": [0, 3, 4], "repo": [0, 2, 3], "initi": 0, "queri": [0, 2, 3, 7], "import": [0, 2, 3, 4, 7, 9], "librari": [0, 2, 3], "torch": [0, 4, 9], "autotoken": [0, 3, 7], "automodelforcausallm": [0, 3, 7], "bitsandbytesconfig": [0, 7], "bitsandbyt": 0, "bnb": 0, "path": [0, 2, 3, 4, 7], "llm_dir": [0, 7, 9], "kellogg": [0, 1, 2, 3, 4, 7, 9, 10], "llm_models_opensourc": [0, 3, 7, 9], "mistral_mistralai": 0, "model_id": 0, "mistralai": [0, 3, 7], "7b": [0, 2, 3, 7], "v0": [0, 3, 7], "bnb_config": 0, "load_in_4bit": 0, "true": [0, 2, 3, 7, 9], "bnb_4bit_use_double_qu": 0, "bnb_4bit_quant_typ": 0, "nf4": 0, "bnb_4bit_compute_dtyp": 0, "bfloat16": 0, "from_pretrain": [0, 3, 7, 9], "quantization_config": [0, 7], "device_map": [0, 3, 7], "cache_dir": [0, 7, 9], "add_eos_token": 0, "function": [0, 2], "def": [0, 3, 7, 9], "get_complet": 0, "str": [0, 2], "devic": [0, 2, 3, 4, 7], "cuda": [0, 2, 7], "prompt_templ": 0, "inst": [0, 3, 7], "one": [0, 1, 4], "four": 0, "class": [0, 3], "sci": 0, "tech": 0, "encod": [0, 3], "return_tensor": [0, 3, 7, 9], "pt": [0, 3, 7, 9], "add_special_token": 0, "model_input": [0, 3, 7], "generated_id": [0, 3], "max_new_token": [0, 3, 7, 9], "1000": [0, 2, 3, 4], "do_sampl": [0, 3, 7, 9], "pad_token_id": 0, "eos_token_id": [0, 2], "decod": [0, 2, 3, 7, 9], "batch_decod": [0, 3], "return": 0, "wall": 0, "st": 0, "bear": 0, "claw": 0, "back": 0, "Into": 0, "black": 0, "reuter": 0, "short": [0, 4], "seller": 0, "street": 0, "dwindl": 0, "band": 0, "ultra": 0, "cynic": 0, "see": [0, 2, 4], "green": 0, "again": 0, "submit": [0, 4], "print": [0, 2, 3, 4, 7, 9], "softwar": [0, 2, 4, 7, 9], "env": [0, 4, 7, 9], "llama2": [0, 3, 9], "lib": 0, "python3": [0, 2, 9], "10": [0, 2, 9], "site": [0, 3, 7], "packag": [0, 9], "diffus": 0, "util": [0, 2], "63": [0, 3], "userwarn": 0, "_pytre": 0, "_register_pytree_nod": 0, "deprec": 0, "pleas": [0, 2, 4, 9], "register_pytree_nod": 0, "instead": [0, 2], "checkpoint": [0, 7, 9], "shard": [0, 7, 9], "100": [0, 3, 7, 9], "00": [0, 2, 3, 4, 7, 9], "12": [0, 2], "30": [0, 2, 4, 7, 9], "32": [0, 2], "A": [0, 2, 4, 7, 9], "onli": [0, 2, 4], "architectur": [0, 1, 2, 4], "being": [0, 2, 4], "right": [0, 2, 3, 7], "pad": [0, 2, 3, 9], "wa": [0, 3], "detect": [0, 2], "For": [0, 1, 2, 3, 4, 7], "correct": 0, "set": [0, 2, 3, 4, 7, 9], "padding_sid": 0, "left": 0, "reason": [0, 4], "discuss": 0, "who": 0, "These": [0, 2], "term": 0, "associ": [0, 9], "financ": 0, "invest": 0, "which": [0, 2, 3, 4, 7, 9], "fall": 0, "within": 0, "mention": 0, "also": [0, 1, 2, 3, 9], "strong": 0, "indic": [0, 4], "articl": 0, "even": [0, 2, 4], "though": [0, 2], "greent": 0, "monei": 0, "doesn": 0, "t": [0, 2, 4, 7, 9], "necessarili": 0, "have": [0, 1, 3, 4, 9], "profit": 0, "capit": 0, "gain": 0, "financi": 0, "market": [0, 9], "addition": 0, "unlik": [0, 2], "contain": [0, 4], "relat": 0, "those": 0, "domain": 0, "notic": 0, "while": [0, 1, 2, 4, 7], "answer": [0, 3], "respons": [0, 2, 3, 4, 7, 9], "veri": [0, 1, 2, 7], "verbos": [0, 9], "prime": 0, "help": [0, 2, 4, 9], "As": 0, "describ": [0, 9], "earlier": 0, "To": [0, 3, 4, 7], "make": [0, 1, 2, 3, 4, 9], "sure": [0, 3, 7, 9], "json": 0, "column": [0, 7], "prefer": [0, 2, 4], "prepare_data": 0, "load_dataset": 0, "creat": [0, 2, 3, 4, 7], "row": [0, 7], "create_text_row": 0, "text_row": 0, "f": [0, 3, 7], "n": [0, 7, 9], "label": 0, "process": [0, 2, 3, 4, 7], "datafram": [0, 7], "jsonl": 0, "process_dataframe_to_jsonl": 0, "output_file_path": 0, "df": [0, 7], "open": [0, 1, 2, 3, 4, 9, 10], "w": [0, 3], "output_jsonl_fil": 0, "_": 0, "iterrow": 0, "json_object": 0, "write": [0, 3], "dump": [0, 2], "split": [0, 2, 3, 7], "train_test_split": 0, "test_siz": 0, "train_data": 0, "test_data": 0, "file": [0, 2, 3, 4, 9], "train_json_fil": 0, "proj": 0, "awc6034": 0, "test_json_fil": 0, "convert": [0, 2, 3, 7], "panda": [0, 7], "train_df": 0, "to_panda": 0, "test_df": 0, "sampl": [0, 2, 9], "head": 0, "christoph": 0, "lee": 0, "becom": 0, "video": [0, 4], "game": 0, "wizard": 0, "law": 0, "must": [0, 1, 4], "respond": 0, "internet": 0, "revolut": 0, "curren": 0, "wood": 0, "give": [0, 2, 10], "up": [0, 1, 2, 3, 4, 7], "number": [0, 2, 4, 9], "vijai": 0, "fame": 0, "nice": 0, "alcoa": 0, "announc": 0, "warn": [0, 2], "u": 0, "aluminium": 0, "india": 0, "laud": 0, "arafat": 0, "lifetim": 0, "devot": 0, "pale": 0, "onc": [0, 3], "pre": [0, 2, 3], "combin": [0, 3], "peft": 0, "paramet": [0, 2, 4, 7], "imagin": [0, 2], "toolbox": 0, "fill": 0, "tool": 0, "standard": 0, "would": 0, "pull": [0, 3], "everi": [0, 1], "try": 0, "adjust": [0, 2, 3, 4], "them": [0, 1, 4], "all": [0, 2, 4], "howev": [0, 2], "adapt": [0, 7], "modul": [0, 2, 4, 7, 9], "like": [0, 1, 2, 4, 7, 9], "toolkit": 0, "focu": [0, 2], "most": [0, 2, 4], "part": [0, 4], "time": [0, 1, 2, 3, 4, 7, 9], "retrain": 0, "everyth": [0, 2], "lora": 0, "rank": 0, "crucial": [0, 2], "identifi": 0, "area": 0, "act": 0, "spotlight": 0, "shine": 0, "kei": [0, 1, 2, 7], "vast": [0, 3], "network": 0, "target": 0, "focus": [0, 7], "sft": 0, "involv": [0, 3], "intern": 0, "abrupt": 0, "chang": 0, "gentler": 0, "approach": [0, 3], "nuanc": 0, "refin": 0, "understand": [0, 3, 4, 9], "drastic": 0, "alter": 0, "exist": [0, 7], "knowledg": [0, 1, 2, 3], "potenti": [0, 2, 4], "overal": 0, "todai": 0, "sfttrainer": 0, "method": [0, 3, 4], "after": [0, 1, 4], "Then": 0, "merg": 0, "togeth": 0, "futur": 0, "benefit": [0, 2], "incorpor": [0, 1, 2, 3], "made": 0, "dure": [0, 2, 3, 9], "trainingargu": 0, "datacollatorforlanguagemodel": 0, "loraconfig": 0, "get_peft_model": 0, "peftmodel": 0, "load_from_disk": 0, "find_all_linear_nam": 0, "cl": 0, "nn": 0, "linear4bit": 0, "lora_module_nam": 0, "name": [0, 2, 3, 7, 9], "named_modul": 0, "isinst": 0, "add": [0, 3, 4], "len": 0, "els": [0, 3, 4], "lm_head": 0, "16": [0, 2, 7], "bit": 0, "remov": 0, "list": 0, "gradient_checkpointing_en": 0, "prepare_model_for_kbit_train": 0, "configur": 0, "lora_config": 0, "r": 0, "8": [0, 2, 7, 9], "lora_alpha": 0, "target_modul": 0, "lora_dropout": 0, "05": [0, 2, 7], "bia": 0, "none": 0, "task_typ": 0, "causal_lm": 0, "calcul": [0, 2, 4], "trainabl": 0, "total": [0, 2], "get_nb_trainable_paramet": 0, "percentag": 0, "4f": 0, "pad_token": 0, "eos_token": 0, "clear": 0, "memori": [0, 1, 2, 4, 7], "cach": 0, "empty_cach": 0, "setup": 0, "start": [0, 1, 2, 3, 4], "trainer": 0, "train_dataset": 0, "eval_dataset": 0, "dataset_text_field": 0, "peft_config": 0, "arg": 0, "per_device_train_batch_s": 0, "gradient_accumulation_step": 0, "warmup_step": 0, "03": [0, 1, 7], "max_step": 0, "learning_r": 0, "2e": 0, "logging_step": 0, "output_dir": 0, "optim": [0, 2, 4], "paged_adamw_8bit": 0, "save_strategi": 0, "epoch": 0, "data_col": 0, "mlm": 0, "fals": [0, 2, 7, 9], "new_model": 0, "push": 0, "hub": [0, 1], "save_pretrain": 0, "base_model": 0, "low_cpu_mem_usag": [0, 9], "return_dict": 0, "torch_dtyp": [0, 9], "float16": [0, 2, 9], "merged_model": 0, "merge_and_unload": 0, "safe_seri": 0, "final": [0, 4], "revisit": 0, "query_finetun": 0, "llm_path": 0, "14": [0, 2], "82": [0, 2], "appear": 0, "still": 0, "slightli": [0, 2], "concis": 0, "beginn": 0, "guid": [0, 2], "run": [0, 1, 3, 4], "qlora": 0, "colab": [0, 4], "finetun": 0, "notebook": [0, 4], "explan": 0, "goal": 1, "look": 1, "practic": 1, "regard": 1, "execut": [1, 4, 7], "sourc": [1, 3, 7, 9, 10], "llm": [1, 3, 9, 10], "quest": [1, 4, 7], "linux": [1, 4], "cluster": [1, 4], "klc": [1, 2, 4], "improv": [1, 2, 3], "extern": [1, 3], "hallucin": [1, 3], "goe": 1, "least": 1, "version": [1, 2], "diagram": [1, 2], "taken": [1, 3], "deeplearn": [1, 7], "ai": [1, 3, 7], "under": [1, 2], "creativ": [1, 7], "common": 1, "licens": 1, "One": [1, 3, 4], "success": 1, "come": [1, 2, 3, 4], "well": [1, 3], "implement": [1, 3], "plan": 1, "specifi": [1, 2, 4], "what": [1, 3], "my": 1, "research": [1, 4, 10], "much": [1, 2, 4], "do": [1, 2, 3, 4], "count": [1, 9], "enough": 1, "support": [1, 3, 10], "often": 1, "somewhat": 1, "underli": 1, "There": [1, 4], "mani": [1, 2, 4], "choic": [1, 2, 4, 9], "avail": [1, 2, 4, 9], "why": [1, 4], "choos": [1, 2], "over": [1, 4], "close": 1, "gpt": [1, 2, 3], "reproduc": [1, 8], "privaci": 1, "flexibl": 1, "infer": [1, 2], "download": [1, 2], "local": 1, "v": 1, "wide": [1, 2, 3], "benchmark": 1, "chatbot": 1, "arena": 1, "2024": [1, 7], "04": [1, 7], "other": [1, 2, 3, 4], "helm": 1, "grow": 1, "capabl": [1, 2], "inspir": 1, "challeng": 1, "an": [1, 2, 4], "faster": [1, 2, 4], "cpu": [1, 2, 9], "show": [1, 4], "order": [1, 2, 4], "mai": [1, 3, 9], "sometim": [1, 4], "wai": [1, 2, 3, 4], "depend": [1, 3, 4], "extract": 1, "precis": [1, 2, 7], "recal": 1, "appropri": [1, 2, 3], "usual": 1, "deploi": [1, 2], "compon": [1, 4], "larger": [1, 3], "deploy": 1, "account": [1, 2, 4], "comput": [1, 2, 7], "suffici": 1, "consum": 1, "amount": [1, 3, 4], "largest": 1, "current": [1, 7], "ha": [1, 2, 4, 7], "fit": 1, "nvidia": [1, 4], "a100": [1, 2, 4, 7, 9], "80gb": [1, 4], "ram": [1, 4], "each": [1, 2], "lot": 1, "contend": 1, "node": [1, 2], "rest": [1, 9], "northwestern": [1, 7], "lower": [1, 2, 7], "fp": 1, "less": [1, 2, 4], "No": 1, "know": [1, 4, 7], "anyth": 1, "about": [1, 2, 3, 7], "event": 1, "occur": 1, "overcom": 1, "obstacl": 1, "fewer": 1, "tranform": [2, 3], "llama": [2, 3, 7], "cpp": 2, "c": 2, "framework": 2, "python": [2, 9], "wrapper": 2, "both": [2, 4, 9], "sinc": 2, "deriv": 2, "thei": [2, 4], "similar": [2, 3], "step": [2, 3], "easier": 2, "detail": [2, 3, 9], "upshot": 2, "tweak": 2, "techniqu": 2, "call": [2, 3, 7], "normal": 2, "stabil": 2, "consid": 2, "akin": 2, "tune": [2, 3, 9], "guitar": 2, "song": 2, "ensur": [2, 9], "string": [2, 3], "tension": 2, "sound": 2, "swiglu": 2, "activ": [2, 4, 7, 9], "pick": 2, "grip": 2, "strum": 2, "chord": 2, "plai": [2, 4], "singl": [2, 4], "posit": 2, "rotari": 2, "embed": [2, 3, 9], "track": 2, "word": [2, 9], "absolut": 2, "fret": 2, "neck": 2, "were": [2, 4], "just": [2, 3], "metal": 2, "bar": 2, "quicker": 2, "fretboard": 2, "addit": [2, 3], "llma_cpp_python": 2, "don": [2, 9], "familiar": 2, "pytorch": [2, 4], "intricaci": 2, "convers": [2, 3], "care": [2, 9], "technic": 2, "hood": 2, "feed": [2, 3], "directli": 2, "load": [2, 3, 4, 7, 9], "send": [2, 4], "either": 2, "plain": 2, "necessari": [2, 3], "build": 2, "block": 2, "store": [2, 3], "multidimension": 2, "arrai": 2, "tensor": [2, 4], "type": [2, 4, 7, 9], "chosen": 2, "float64": 2, "integ": 2, "impact": [2, 7], "think": 2, "digit": 2, "repres": [2, 7, 9], "e": 2, "g": 2, "offer": [2, 4], "greater": 2, "speed": [2, 4], "introduc": 2, "slight": 2, "trade": 2, "simplifi": 2, "input": [2, 3, 4, 9], "compress": 2, "unifi": [2, 4], "leverag": [2, 4], "further": 2, "essenti": 2, "imag": [2, 4], "By": 2, "limit": 2, "power": [2, 3, 4], "quantizaton": 2, "size": [2, 9], "feasibl": 2, "own": [2, 3, 4, 7], "possibl": [2, 4, 9], "found": [2, 3], "theblok": 2, "suggest": 2, "primarili": 2, "fine": [2, 3, 9], "comprehens": 2, "develop": 2, "experiment": 2, "slower": 2, "small": 2, "overhead": [2, 4], "outweigh": 2, "tini": 2, "loss": 2, "neglig": 2, "applic": 2, "high": 2, "full": 2, "could": [2, 3, 4], "advanc": [2, 9], "llama_cpp": [2, 9], "model_path": 2, "context_s": 2, "512": [2, 3], "max_tokens_select": 2, "temperature_select": 2, "float": 2, "top_p_select": 2, "9": 2, "top_k_select": 2, "int": 2, "summari": [2, 3], "gui": 2, "debord": 2, "societ": 2, "du": 2, "spectacl": 2, "kind": [2, 4], "pickup": 2, "esp": 2, "ltd": 2, "alexi": 2, "rip": 2, "written": 2, "prompt_sytnax": 2, "start_of_turn": 2, "user": [2, 3, 9], "end_of_turn": 2, "n_ctx": [2, 9], "max": 2, "sequenc": 2, "length": [2, 3], "n_thread": [2, 9], "thread": 2, "n_gpu_lay": [2, 9], "want": [2, 3], "max_token": 2, "temperatur": [2, 7], "top_p": 2, "top_k": 2, "echo": 2, "response_text": 2, "option": [2, 4, 7], "At": 2, "window": 2, "default": 2, "pass": 2, "maximum": 2, "valu": [2, 7], "rang": [2, 3], "determinist": 2, "end": 2, "random": [2, 4], "control": 2, "divers": [2, 3], "predict": [2, 3], "mean": [2, 3, 4], "select": [2, 3, 4], "probabl": 2, "whose": 2, "cumul": 2, "exce": 2, "given": [2, 3, 4], "threshold": 2, "zero": 2, "increas": 2, "chanc": 2, "boolean": 2, "determin": [2, 4], "whether": [2, 3, 4], "includ": [2, 7], "origin": 2, "begin": 2, "ones": 2, "readthedoc": 2, "io": 2, "en": [2, 3], "latest": [2, 4], "api": 2, "gemma_test": 2, "directori": [2, 3, 7, 9], "bound": 2, "slurm": [2, 9], "bin": [2, 4, 7, 9], "bash": [2, 4, 7, 9], "sbatch": [2, 4, 7, 9], "e32337": [2, 4, 7], "partit": [2, 4], "gengpu": [2, 4, 7, 9], "ntask": [2, 4], "per": [2, 4], "gre": [2, 4, 7, 9], "mem": [2, 4, 7, 9], "40g": [2, 4, 7, 9], "purg": [2, 4, 7, 9], "modulefil": [2, 4, 9], "38": [2, 9], "ggml_init_cubla": 2, "disabl": 2, "llama_model_load": 2, "meta": [2, 3, 7], "19": 2, "pair": 2, "254": 2, "v3": 2, "metadata": 2, "kv": 2, "overrid": 2, "context_length": 2, "u32": 2, "8192": 2, "block_count": 2, "28": 2, "embedding_length": 2, "3072": 2, "5": [2, 3, 7, 9], "feed_forward_length": 2, "24576": 2, "6": [2, 4], "attent": 2, "head_count": 2, "7": 2, "head_count_kv": 2, "key_length": 2, "256": 2, "value_length": 2, "layer_norm_rms_epsilon": 2, "f32": 2, "000001": 2, "11": [2, 7], "ggml": 2, "bos_token_id": 2, "13": 2, "padding_token_id": 2, "15": 2, "unknown_token_id": 2, "arr": 2, "256128": 2, "eo": 2, "bo": 2, "unk": 2, "17": 2, "score": 2, "000000": 2, "0000": 2, "18": [2, 4], "token_typ": 2, "i32": 2, "llm_load_vocab": 2, "mismatch": 2, "definit": 2, "544": 2, "388": 2, "llm_load_print_meta": 2, "arch": 2, "vocab": 2, "spm": 2, "n_vocab": 2, "n_merg": 2, "n_ctx_train": 2, "n_embd": 2, "n_head": 2, "n_head_kv": 2, "n_layer": 2, "n_rot": 2, "192": 2, "n_embd_head_k": 2, "n_embd_head_v": 2, "n_gqa": 2, "n_embd_k_gqa": 2, "4096": [2, 3], "n_embd_v_gqa": 2, "f_norm_ep": 2, "0e": 2, "f_norm_rms_ep": 2, "06": 2, "f_clamp_kqv": 2, "f_max_alibi_bia": 2, "n_ff": 2, "n_expert": 2, "n_expert_us": 2, "rope": 2, "scale": 2, "linear": 2, "freq_base_train": 2, "10000": 2, "freq_scale_train": 2, "n_yarn_orig_ctx": 2, "rope_finetun": 2, "unknown": 2, "ftype": 2, "guess": 2, "param": 2, "54": 2, "b": 2, "31": 2, "81": [2, 7], "gib": 2, "bpw": 2, "lf": 2, "227": 2, "0x0a": 2, "llm_load_tensor": 2, "ctx": 2, "mib": 2, "offload": 2, "repeat": 2, "layer": 2, "non": 2, "29": 2, "buffer": 2, "32570": 2, "llama_new_context_with_model": 2, "freq_bas": 2, "freq_scal": 2, "fail": 2, "alloc": [2, 4], "224": 2, "mb": 2, "pin": 2, "llama_kv_cache_init": 2, "self": [2, 7], "k": 2, "f16": 2, "112": 2, "01": [2, 9], "506": 2, "25": [2, 9], "cuda_host": 2, "graph": 2, "measur": 2, "avx": 2, "avx_vnni": 2, "avx2": 2, "avx512": 2, "avx512_vbmi": 2, "avx512_vnni": 2, "fma": 2, "neon": 2, "arm_fma": 2, "f16c": 2, "fp16_va": 2, "wasm_simd": 2, "bla": 2, "sse3": 2, "ssse3": 2, "vsx": 2, "matmul_int8": 2, "llama_print_tim": 2, "1047": 2, "55": 2, "m": [2, 3, 7], "111": 2, "74": 2, "34": 2, "304": 2, "second": [2, 7], "eval": 2, "37": 2, "69": 2, "136433": 2, "33": 2, "4134": 2, "24": [2, 4], "138373": 2, "07": 2, "48": [2, 7], "ripper": 2, "ceram": 2, "humbuck": 2, "coil": 2, "tap": 2, "clean": 2, "overdr": 2, "check": [2, 3, 4, 7], "misral_test": 2, "llama2_test": 2, "git": 2, "tuturi": 2, "adn": 2, "paradigm": 3, "natur": 3, "strength": 3, "dataset": 3, "accur": [3, 9], "phrase": 3, "recent": 3, "paper": 3, "lewi": 3, "et": 3, "al": 3, "facebook": 3, "idea": 3, "model": [3, 10], "lm": 3, "separ": [3, 4], "system": [3, 4, 7], "condit": 3, "question": [3, 4], "agent": 3, "multipl": 3, "pdf": 3, "csv": [3, 7], "creation": 3, "assist": [3, 9], "snippet": 3, "prevent": 3, "bring": 3, "finish": [3, 7], "reli": 3, "url": 3, "txt": 3, "locat": [3, 4], "s3": 3, "public": 3, "etc": [3, 7, 9], "prepar": 3, "chunk": [3, 4], "emb": 3, "captur": 3, "semant": 3, "later": [3, 4], "enabl": 3, "piec": 3, "vector": [3, 4], "search": 3, "awar": 3, "runtim": 3, "blend": 3, "rich": 3, "content": [3, 9], "doc": 3, "llamaindex": 3, "stabl": 3, "_static": 3, "getting_start": 3, "basic_rag": 3, "png": 3, "between": [3, 9], "januari": 3, "2023": 3, "juli": 3, "releas": 3, "septemb": 3, "let": [3, 4], "chat": [3, 7], "test_llama2": [3, 7], "instal": 3, "bertmodel": 3, "uncas": 3, "input_text": 3, "input_id": 3, "attention_mask": 3, "max_length": 3, "truncat": 3, "interpret": 3, "sens": [3, 9], "consult": 3, "page": 3, "webpag": 3, "outlin": 3, "abov": [3, 9], "pathlib": [3, 7], "log": [3, 7], "sy": 3, "llama_index": 3, "core": [3, 9], "vectorstoreindex": 3, "simpledirectoryread": 3, "storagecontext": 3, "load_index_from_storag": 3, "node_pars": 3, "sentencesplitt": 3, "huggingfacellm": 3, "huggingfaceembed": 3, "vector_stor": 3, "faiss": 3, "faissvectorstor": 3, "bs4": 3, "beautifulsoup": 3, "o": 3, "start_tim": 3, "link": 3, "prep_text": 3, "workdir": 3, "url_link": 3, "soup": 3, "html": 3, "parser": 3, "webpage_cont": 3, "get_text": 3, "strip": 3, "linesep": 3, "join": 3, "splitlin": 3, "data_path": 3, "llamaindex_data": 3, "mkdir": 3, "txt_file": 3, "process_llamaindex": 3, "embedding_nam": 3, "embed_d": 3, "llm_model": [3, 7, 9], "basicconfig": 3, "stream": [3, 4, 9], "stdout": [3, 4], "level": 3, "info": [3, 7], "getlogg": 3, "addhandl": 3, "streamhandl": 3, "embedding_chunk_s": 3, "1024": 3, "embed_model": 3, "model_nam": 3, "context_window": 3, "tokenizer_nam": 3, "auto": [3, 7], "persist_dir": 3, "llamaindex_storage_faiss": 3, "load_data": 3, "faiss_index": 3, "indexflatl2": 3, "storage_context": 3, "from_default": 3, "index": [3, 7], "from_docu": 3, "chunk_siz": 3, "persist": 3, "from_persist_dir": 3, "query_engin": 3, "as_query_engin": 3, "replac": 3, "your_file_directori": 3, "project": [3, 4, 7], "file_dir": 3, "intfloat": 3, "multilingu": 3, "e5": 3, "e5_infloat": 3, "snapshot": 3, "baa7be480a7de1539afce709c8f13f833a510e0a": 3, "dimens": 3, "llama2_7b_chat": 3, "llama2_meta_huggingfac": [3, 7], "hf": [3, 7, 9], "92011f62d7604e261f748ec0cfe6329f31193e33": 3, "llama2_13b_chat": 3, "13b": [3, 7], "29655417e51232f4f2b9b5d3e1418e5a9b04e80": 3, "batch": 3, "51it": 3, "pip": 3, "termin": [3, 4], "apply_chat_templ": 3, "messag": [3, 9], "role": [3, 9], "favourit": 3, "condiment": 3, "quit": 3, "partial": 3, "squeez": 3, "fresh": 3, "lemon": 3, "juic": 3, "zesti": 3, "flavour": 3, "whatev": 3, "cook": 3, "kitchen": 3, "mayonnais": 3, "recip": 3, "hyperparamet": 3, "ad": [3, 9], "placehold": 3, "actual": [3, 4], "so": [4, 7], "temporari": 4, "afterward": 4, "googl": [4, 7], "free": 4, "browser": 4, "cloud": 4, "platform": 4, "amazon": 4, "web": 4, "servic": 4, "microsoft": 4, "azur": 4, "price": 4, "sprung": 4, "paperspac": 4, "bui": 4, "budget": 4, "expertis": 4, "equip": 4, "processor": [4, 9], "graphic": 4, "card": 4, "central": 4, "unit": 4, "mathemat": 4, "logic": 4, "nutshel": 4, "extrem": 4, "infinitesim": 4, "thing": 4, "across": 4, "solv": 4, "problem": 4, "simultan": 4, "distribut": 4, "64": 4, "2tb": 4, "share": 4, "theori": 4, "hardwar": 4, "oper": 4, "comparison": 4, "912": 4, "h100": 4, "astound": 4, "432": 4, "individu": 4, "sheer": 4, "volum": 4, "ideal": 4, "certain": 4, "matrix": 4, "design": 4, "speedup": 4, "If": 4, "aren": 4, "simpli": 4, "anoth": 4, "serial": 4, "longer": 4, "coordin": 4, "alon": 4, "ineffici": 4, "rais": 4, "On": 4, "intens": 4, "deleg": 4, "magnitud": 4, "test": 4, "cours": [4, 7], "repositori": 4, "is_avail": 4, "device_count": 4, "get_device_nam": 4, "accordingli": 4, "two": [4, 7], "tensor1": 4, "randn": 4, "tensor2": 4, "jupyt": 4, "dozen": 4, "via": 4, "demand": 4, "schedul": 4, "exclus": 4, "commun": 4, "ident": 4, "job": 4, "launch": 4, "constraint": 4, "pcie": 4, "j": 4, "append": [4, 7], "micromamba": 4, "load_hook": 4, "direct": 4, "genom": 4, "line": [4, 7], "paralleliz": 4, "otherwis": 4, "slow": 4, "sxm": 4, "40gb": 4, "minut": 4, "stderr": 4, "environ": 4, "interfac": 4, "shown": [4, 9], "command": 4, "explain": 4, "teach": 7, "materi": 7, "pd": 7, "run_llama2": 7, "customize_set": 7, "uncom": 7, "comment": 7, "load_in_8bit": 7, "custom": 7, "item": 7, "skip_special_token": [7, 9], "finished_tim": 7, "strftime": 7, "y": 7, "d": [7, 9], "h": 7, "localtim": 7, "llm_name": 7, "log_fil": 7, "log_": 7, "to_csv": 7, "mode": 7, "header": 7, "space": 7, "70b": 7, "enclos": 7, "tell": 7, "fun": 7, "fact": 7, "school": 7, "400": [7, 9], "p": [7, 9], "mamba": [7, 9], "23": [7, 9], "hpc": [7, 9], "profil": [7, 9], "conda": [7, 9], "sh": [7, 9], "50": 7, "08": 7, "98": 7, "65569519996643": 7, "manag": 7, "univers": 7, "did": 7, "campu": 7, "ic": 7, "cream": 7, "shop": 7, "ye": 7, "read": 7, "popular": 7, "spot": 7, "student": 7, "indulg": 7, "sweet": 7, "tooth": 7, "enjoi": 7, "varieti": 7, "flavor": 7, "uniqu": 7, "chocol": 7, "chip": 7, "cooki": 7, "dough": 7, "cinnamon": 7, "swirl": 7, "food": 7, "societi": 7, "social": 7, "cultur": 7, "next": 7, "re": 7, "stop": 7, "treat": 7, "751539945602417": 7, "test_mistr": 7, "test_gemma": 7, "form": 8, "principl": 8, "pil": 9, "autoprocessor": 9, "llavaforconditionalgener": 9, "llava": 9, "v1": 9, "run_bakllava": 9, "image_fil": 9, "raw_imag": 9, "raw": 9, "nyou": 9, "mom": 9, "survei": 9, "diaper": 9, "appeal": 9, "nassist": 9, "i5": 9, "walmartimag": 9, "com": 9, "seo": 9, "babi": 9, "newborn": 9, "lb": 9, "120": 9, "pamper": 9, "swaddler": 9, "onemonth": 9, "suppli": 9, "vary_95ea2d1c": 9, "769a": 9, "4ec2": 9, "8da8": 9, "7e6ea4829e55": 9, "3c890f8095b5b30ae263c996151f9575": 9, "jpeg": 9, "runn": 9, "your_quest_allocation_account": 9, "test_bakllava": 9, "61it": 9, "75": 9, "81it": 9, "02it": 9, "been": 9, "vocabulari": 9, "er": 9, "me": 9, "featur": 9, "heartwarm": 9, "parent": 9, "hold": 9, "evok": 9, "feel": 9, "love": 9, "joi": 9, "parenthood": 9, "comfort": 9, "secur": 9, "warmth": 9, "infant": 9, "sooth": 9, "colicki": 9, "sleep": 9, "connect": 9, "tender": 9, "moment": 9, "brand": 9, "bond": 9, "live": 9, "llm_core": 9, "llavacppmodel": 9, "q4_k_m": 9, "gguf": 9, "llama_cpp_kwarg": 9, "logits_al": 9, "8000": 9, "clip_model_path": 9, "clip": 9, "load_model": 9, "histori": 9, "image_url": 9, "stack": 9, "asset": 9, "img": 9, "mappemond": 9, "jpg": 9, "home": 9, "image_test": 9, "websit": 10, "cookbook": 10, "book": 10, "aim": 10}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"fine": [0, 1], "tune": [0, 1], "font": [0, 2, 3, 4, 7, 9], "color": [0, 2, 3, 4, 7, 9], "purpl": [0, 2, 3, 4, 7, 9], "tradeoff": [0, 2], "between": [0, 2], "techniqu": 0, "load": 0, "test": 0, "origin": 0, "model": [0, 1, 2, 7, 9], "prepar": 0, "dataset": 0, "step": 0, "refer": [0, 2, 4], "sourc": [0, 2, 4], "introduct": 1, "object": 1, "project": 1, "lifecycl": 1, "defin": 1, "us": [1, 2, 3, 4, 7, 8], "case": [1, 3, 8], "type": 1, "select": 1, "leaderboard": 1, "adapt": 1, "evalu": 1, "metric": 1, "applic": 1, "integr": 1, "optim": 1, "retriev": [1, 3], "augment": [1, 3], "gener": [1, 3], "rag": 1, "llama_cpp_python": [2, 9], "run": [2, 7, 9], "llm": [2, 4, 5, 7], "v": 2, "transform": [2, 7, 9], "basic": [2, 7], "workflow": [2, 7], "quantiz": 2, "what": 2, "i": 2, "gguf": 2, "tool": 2, "gemma": [2, 7], "mistral": [2, 7], "llama2": [2, 7], "sampl": [3, 4], "how": 3, "work": 3, "exampl": [3, 8], "inform": 3, "non": 3, "exist": 3, "train": 3, "script": [3, 4, 7], "gpu": 4, "northwestern": 4, "parallel": 4, "comput": 4, "cpu": 4, "multipl": 4, "core": 4, "cuda": 4, "python": [4, 7], "code": 4, "pytorch_gpu_test": 4, "py": 4, "resourc": 4, "slurm": [4, 7], "access": 4, "node": 4, "sh": 4, "break": 4, "down": 4, "thi": 4, "survei": 5, "summari": 6, "takeawai": 6, "10k": 8, "process": [8, 9], "imag": 9, "bakllava": 9, "welcom": 10}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 60}, "alltitles": {"Fine-Tuning": [[0, "fine-tuning"]], "<font color='purple'>Tradeoffs between Techniques</font>": [[0, "tradeoffs-between-techniques"]], "<font color='purple'>Load and Test Original Model</font>": [[0, "load-and-test-original-model"]], "<font color='purple'>Prepare Dataset</font>": [[0, "prepare-dataset"]], "<font color='purple'>Fine Tuning Steps</font>": [[0, "fine-tuning-steps"]], "<font color='purple'>Techniques</font>": [[0, "techniques"]], "<font color='purple'>Fine-Tuning Steps</font>": [[0, "id1"]], "<font color='purple'>Test Fine-Tuned Model</font>": [[0, "test-fine-tuned-model"]], "<font color='purple'>Reference Sources</font>": [[0, "reference-sources"], [2, "reference-sources"], [4, "reference-sources"]], "Introduction": [[1, "introduction"]], "Objective": [[1, null]], "Project Lifecycle": [[1, null]], "Define the Use Case": [[1, "define-the-use-case"]], "Types of Use Cases": [[1, null]], "Select a Model": [[1, "select-a-model"]], "Leaderboards": [[1, null]], "Adapt the Model: Fine-tuning": [[1, "adapt-the-model-fine-tuning"]], "Evaluation Metrics": [[1, null]], "Application Integration": [[1, "application-integration"]], "Model Optimization": [[1, null]], "Retrieval Augmented Generation (RAG)": [[1, null]], "Using Llama_cpp_python to run LLMs": [[2, "using-llama-cpp-python-to-run-llms"]], "<font color='purple'>Llama_cpp_python vs. Transformers</font>": [[2, "llama-cpp-python-vs-transformers"]], "<font color='purple'>Basic Workflow for llama_cpp_python</font>": [[2, "basic-workflow-for-llama-cpp-python"]], "<font color='purple'>Quantized Models - What is GGUF?</font>": [[2, "quantized-models-what-is-gguf"]], "<font color='purple'>Tradeoffs between Tools</font>": [[2, "tradeoffs-between-tools"]], "<font color='purple'>Run Gemma model</font>": [[2, "run-gemma-model"]], "<font color='purple'>Run Mistral model</font>": [[2, "run-mistral-model"]], "<font color='purple'>Run llama2 model</font>": [[2, "run-llama2-model"]], "Retrieval Augmented Generation": [[3, "retrieval-augmented-generation"]], "<font color='purple'>Sample Uses Cases</font>": [[3, "sample-uses-cases"]], "<font color='purple'>How it Works</font>": [[3, "how-it-works"]], "<font color='purple'>Example: Retrieving Information Non-existent in Training</font>": [[3, "example-retrieving-information-non-existent-in-training"]], "<font color='purple'>Sample scripts</font>": [[3, "sample-scripts"]], "Using GPUs at Northwestern": [[4, "using-gpus-at-northwestern"]], "Parallel Computing for LLMs": [[4, "parallel-computing-for-llms"]], "<font color='purple'>CPUs</font>": [[4, null]], "<font color='purple'>Multiple CPU Cores</font>": [[4, null]], "<font color='purple'>GPUs</font>": [[4, null]], "<font color='purple'>CUDA</font>": [[4, null]], "Sample GPU Python Code": [[4, "sample-gpu-python-code"]], "pytorch_gpu_test.py": [[4, null]], "<font color='purple'>Northwestern GPU Resources</font>": [[4, null]], "SLURM Script to Access GPU Nodes": [[4, "slurm-script-to-access-gpu-nodes"]], "<font color='purple'>pytorch_gpu_test.sh</font>": [[4, null]], "<font color='purple'>Breaking down this script</font>": [[4, null]], "LLMs for Survey": [[5, "llms-for-survey"]], "Summary and Takeaways": [[6, "summary-and-takeaways"]], "Using Transformers to run LLMs": [[7, "using-transformers-to-run-llms"]], "<font color='purple'>Basic workflow for using transformers</font>": [[7, "basic-workflow-for-using-transformers"]], "<font color='purple'>Run Llama2 model with transformers</font>": [[7, "run-llama2-model-with-transformers"]], "Python script": [[7, "python-script"]], "Slurm script": [[7, "slurm-script"]], "<font color='purple'>Run Mistral model with transformers</font>": [[7, "run-mistral-model-with-transformers"]], "<font color='purple'>Run Gemma model with transformers</font>": [[7, "run-gemma-model-with-transformers"]], "Example Use Case": [[8, "example-use-case"]], "10K Processing": [[8, "k-processing"]], "Process Images with bakllava": [[9, "process-images-with-bakllava"]], "<font color='purple'>Run bakllava model with transformers</font>": [[9, "run-bakllava-model-with-transformers"]], "<font color='purple'>Run bakllava model with llama_cpp_python</font>": [[9, "run-bakllava-model-with-llama-cpp-python"]], "Welcome": [[10, "welcome"]]}, "indexentries": {}})