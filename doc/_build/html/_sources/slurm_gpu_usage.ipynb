{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>SLURM Jobs and GPU Usage</font>\n",
    "\n",
    "The open-source LLMs can consist of model and model weights with billions of parameters.  In order to speed up the processing, we will be running these models on Quest GPU nodes. To access these nodes, you will need a Quest allocation. You can request a Quest allocation here: https://www.it.northwestern.edu/departments/it-services-support/research/computing/quest/general-access-allocation-types.html.  \n",
    "\n",
    "Today, we'll submit jobs to the Quest GPU nodes through a <font color='purple'>SLURM</font> (scheduler) script.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>1.) Sample Python Code</font>\n",
    "\n",
    "To get started with the GPU nodes, here is some sample Python script. The code below allows you to test whether GPUs are available and runs tensors. This file is located in <font color='purple'>__/kellogg/admin/gpu_test_files/pytorch_gpu_test.py__</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pytorch_gpu_test.py\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print whether a GPU or CPU is being used\n",
    "if device.type == 'cuda':\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Create two random tensors\n",
    "tensor1 = torch.randn(1000, 1000, device=device)\n",
    "tensor2 = torch.randn(1000, 1000, device=device)\n",
    "\n",
    "# Add the two tensors, the operation will be performed on the GPU if available\n",
    "result = tensor1 + tensor2\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>2.) SLURM Script</font>\n",
    "\n",
    "So long as you have a Quest allocation, you can launch the sample python code using this SLURM script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -A your_quest_allocation_account\n",
    "#SBATCH -p gengpu\n",
    "#SBATCH --gres=gpu:a100:1\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 1\n",
    "#SBATCH -t 0:30:00\n",
    "#SBATCH --mem=40G\n",
    "\n",
    "module purge\n",
    "module load python\n",
    "source activate /kellogg/software/envs/gpu-pytorch\n",
    "python pytorch_gpu_test.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking down this script: \n",
    "\n",
    "- `srun' is used to submit an interactive job to the Slurm scheduler.\n",
    "- `--partition=gengpu` directs you to GPU nodes on the Quest Genomics Cluster\n",
    "- `--account=XXXXX` must reference the Quest allocation you are given.\n",
    "- `--nodes=1` specifies that the job will be run on 1 node of the cluster.  Since there is only 1 GPU node available this cannot be adjusted.\n",
    "- `--ntasks-per-node=1` this line specifies how many cores of the node you will use. Setting `--ntasks-per-node=2` will run your script on two cores of the node. Only adjust this parameter if your code is parallelizable, otherwise it will slow down the processing speed. \n",
    "- `--gres=gpu:a100:1` GRES stand for `Generic Resources'. This line specifies that the job requires 1 GPU of type \"a100\".  By excluding this line, your job will be restricted to CPU resources.\n",
    "- `--time==00:30:00` indicates that this job will be allowed to run for up to 30 minutes.\n",
    "- `--mem` specifies how much memory you are requesting. \n",
    "\n",
    "After accessing the GPU node, the script loads python and activates the <font color='purple'>__gpu-pytorch__</font> environment.  Finally it launches the python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting your job, you will receive a job ID, like: \n",
    "\n",
    "<font color='purple'>__Submitted batch job 9428806__</font> \n",
    "\n",
    "Once the script runs to completion, the results will be saved to a __slurm-[job_iD].out__ file, (like __slurm-9428806.out__) in your current directory. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
