{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use Case: 10K Processing\n",
    "\n",
    ":::{admonition} [10-K filings](https://www.investopedia.com/terms/1/10-k.asp)\n",
    ":class: important\n",
    "\n",
    "Our objective: produce summaries of (portions of) 10-K filings\n",
    "\n",
    "```{figure} ./images/10-K-investopedia.png\n",
    "---\n",
    "width: auto\n",
    "name: 10-K-investopedia\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} All 10-K documents are available on KLC (up to 2024)\n",
    "\n",
    "```{figure} ./images/10-K-klc.png\n",
    "---\n",
    "width: 900px\n",
    "name: 10-K-klc\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Find a Model\n",
    "\n",
    "We can search for a summarization model on the [Hugging Face Model Hub](https://huggingface.co/Falconsai/text_summarization)\n",
    "\n",
    "```{figure} ./images/model-hub-summarize.png\n",
    "---\n",
    "width: auto\n",
    "name: model-hub-summarize\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} Create a Summarization Pipeline\n",
    "```python\n",
    "def main(num_files=10):\n",
    "    # get listing of 10K files\n",
    "    files = list(input_dir.glob(\"*.txt\"))[:num_files]\n",
    "    files.sort()\n",
    "\n",
    "    # load and clean text, extr\n",
    "    data_dict = {\"doc\": [], \"text\": []}\n",
    "    for f in files:\n",
    "        print(f\"loading: {f.name}\")\n",
    "        text = clean_html(f.read_text())\n",
    "        mda_text = extract_mda(text)\n",
    "        if mda_text is None:\n",
    "            continue\n",
    "        data_dict[\"doc\"].append(f.name)\n",
    "        data_dict[\"text\"].append(mda_text)\n",
    "\n",
    "    # create a dataset object\n",
    "    dataset_10k = Dataset.from_dict(data_dict)\n",
    "    print(f\"created dataset: {dataset_10k}\")\n",
    "\n",
    "    # apply summarization pipeline to dataset\n",
    "    summarizer = pipeline(\"summarization\", model=model_checkpoint)\n",
    "    dataset_10k = dataset_10k.map(\n",
    "        lambda batch: {\n",
    "            \"summary\": summarizer(\n",
    "                batch[\"text\"],\n",
    "                max_length=100,\n",
    "                min_length=30,\n",
    "                do_sample=False,\n",
    "                truncation=True,\n",
    "            )\n",
    "        },\n",
    "        batched=True,\n",
    "    )\n",
    "\n",
    "    # output to file\n",
    "    dataset_10k.to_csv(output_file)\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{toggle}\n",
    "```python\n",
    "def clean_html(html):\n",
    "    # First we remove inline JavaScript/CSS:\n",
    "    cleaned = re.sub(r\"(?is)<(script|style).*?>.*?(</\\1>)\", \"\", html.strip())\n",
    "    \n",
    "    # Then we remove html comments. This has to be done before removing regular\n",
    "    # tags since comments can contain '>' characters.\n",
    "    cleaned = re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", \"\", cleaned)\n",
    "    \n",
    "    # Next we can remove the remaining tags:\n",
    "    cleaned = re.sub(r\"(?s)<.*?>\", \" \", cleaned)\n",
    "    \n",
    "    # Finally, we deal with whitespace\n",
    "    cleaned = re.sub(r\"&nbsp;\", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"  \", \" \", cleaned)\n",
    "    cleaned = re.sub(r\"  \", \" \", cleaned)\n",
    "    return cleaned.strip()\n",
    "```\n",
    ":::\n",
    "\n",
    ":::{toggle}\n",
    "```python\n",
    "def extract_mda(text):\n",
    "    mda_text = None\n",
    "    \n",
    "    # obtain the second occurrence of \"Discussion and Analysis of Financial Condition\" with wildcards\n",
    "    pattern = r\"Discussion[\\s,.-]*and[\\s,.-]*Analysis[\\s,.-]*of[\\s,.-]*Financial[\\s,.-]*Condition\"\n",
    "    mda_matches = list(re.finditer(pattern, text, re.IGNORECASE))\n",
    "    if len(mda_matches) >= 2:\n",
    "        m = mda_matches[1]\n",
    "        mda_text = text[m.end():]\n",
    "        return \" \".join(mda_text.split()[:250])\n",
    "    return mda_text\n",
    "```\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}