{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing  \n",
    "\n",
    "There are also open-source models available to run image processing.  One such model called <font color='purple'>BakLLaVa</font> is described in more detail here: https://github.com/SkunkworksAI/BakLLaVA.  You can download it from Hugging Face here: https://huggingface.co/llava-hf/bakLlava-v1-hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='purple'>Toy Marketing Study</font>  \n",
    "\n",
    "You can run this model using both transformers and llama_cpp_python. We showcase how to deploy it with transformers below in the context of a toy marketing study.\n",
    "\n",
    "For the toy study, we asked DALLE to produce 3 soft drink ads for us:\n",
    "\n",
    "**1. with cute kawaii characters**\n",
    "\n",
    "**2. with people at a Cubs game enjoying the drink** \n",
    "\n",
    "**3. from a hopeless dystopian future, where the soft drink looks like it might taste good** \n",
    "\n",
    "This is what it provided:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sodas](./images/sodas.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we gave the model the following prompt: \"_You are thirsty young adult between age 25 and 30 taking a marketing survey.\n",
    "Can you describe if this soft drink ad appeals to you?_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='purple'>Run image model with transformers</font>  \n",
    "\n",
    "For this study, we'll run the model with transformers using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Toy Marketing Study - Does this ad appeal to you?\n",
    "###################################################\n",
    "# libraries\n",
    "import torch\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "#########\n",
    "# Inputs\n",
    "#########\n",
    "\n",
    "llm_model = \"llava-hf/bakLlava-v1-hf\"\n",
    "llm_dir = \"/kellogg/data/llm_models_opensource/bakLlava\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "USER: <image>\\nYou are thirsty young adult between age 25 and 30 taking a marketing survey.\n",
    "Can you describe if this soft drink ad appeals to you?\n",
    "\\nASSISTANT:\n",
    "\"\"\"\n",
    "\n",
    "output_file = \"/kellogg/software/llama_cpp/output/ad_results.csv\"\n",
    "ad_dir = \"/kellogg/software/llama_cpp/code/ads\"\n",
    "\n",
    "\n",
    "############\n",
    "# Functions\n",
    "############\n",
    "\n",
    "# load model and processor\n",
    "def load_model(llm_model, llm_dir):\n",
    "    model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        llm_model,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "        cache_dir=llm_dir,\n",
    "    ).to(0)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(llm_model)\n",
    "\n",
    "    return model, processor\n",
    "\n",
    "# run bakllava\n",
    "def run_bakllava(model, processor, image_file, prompt):\n",
    "    # open image\n",
    "    raw_image = Image.open(image_file)\n",
    "\n",
    "    # process image\n",
    "    inputs = processor(prompt, raw_image, return_tensors='pt').to(0, torch.float16)\n",
    "\n",
    "    # generate response\n",
    "    output = model.generate(**inputs, max_new_tokens=400, do_sample=False)\n",
    "    output = processor.decode(output[0][2:], skip_special_tokens=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "# save results to a df\n",
    "def save_results(prompt, image_file, response, run_time):\n",
    "\n",
    "    # create empty df\n",
    "    results_df = pd.DataFrame(columns=['prompt', 'image_file', 'response', 'run_time'])\n",
    "\n",
    "    # create df from current row\n",
    "    row_df = pd.DataFrame({\n",
    "        'prompt': [prompt],\n",
    "        'image_file': [image_file],\n",
    "        'response': [response],\n",
    "        'run_time': [run_time]\n",
    "    })\n",
    "\n",
    "    # combine\n",
    "    results_df = pd.concat([results_df, row_df], ignore_index=True)\n",
    "\n",
    "    # return dataframe\n",
    "    return results_df\n",
    "\n",
    "\n",
    "######\n",
    "# RUN\n",
    "######\n",
    "\n",
    "def main():\n",
    "   # list of files from a directory\n",
    "    ads = [os.path.join(ad_dir, f) for f in os.listdir(ad_dir) if os.path.isfile(os.path.join(ad_dir, f))]\n",
    "\n",
    "    # load model\n",
    "    model, processor = load_model(llm_model, llm_dir)\n",
    "\n",
    "    # loop over\n",
    "    for ad in ads:\n",
    "        # run\n",
    "        start_time = time.time()\n",
    "        response = run_bakllava(model, processor, ad, prompt)\n",
    "        run_time = time.time() - start_time\n",
    "\n",
    "        # print results\n",
    "        print(\"========================\")\n",
    "        print(f\"Ad: {ad}\")\n",
    "        print(f\"Response: {response}\")\n",
    "        print(f\"Run Time: {run_time}\")\n",
    "        print(\"========================\")\n",
    "\n",
    "        # save progress\n",
    "        results_df = save_results(prompt, ad, response, run_time)\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample SLURM script for runnning the python code provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -A your_quest_allocation_account\n",
    "#SBATCH -p gengpu\n",
    "#SBATCH --gres=gpu:a100:1\n",
    "#SBATCH -N 1\n",
    "#SBATCH -n 1\n",
    "#SBATCH -t 0:30:00\n",
    "#SBATCH --mem=40G\n",
    "\n",
    "module purge\n",
    "module load mamba/23.1.0\n",
    "source /hpc/software/mamba/23.1.0/etc/profile.d/conda.sh\n",
    "source activate /kellogg/software/envs/gpu-llama2\n",
    "\n",
    "python image_workflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output:__ \n",
    "```\n",
    "\n",
    "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.70it/s]\n",
    "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
    "========================\n",
    "\n",
    "Ad: /kellogg/software/llama_cpp/code/ads/dystopia.png\n",
    "Response: \n",
    "USER:  \n",
    "You are thirsty young adult between age 25 and 30 taking a marketing survey. \n",
    "Can you describe if this soft drink ad appeals to you?\n",
    "\n",
    "ASSISTANT:\n",
    "The image features a red can of Coca-Cola in a visually appealing setting. It is placed in front of a futuristic city landscape, possibly on a beach or near a building. The contrast between the red can and the surrounding environment creates a striking visual effect. The scene suggests that the soft drink brand is targeting a young adult audience, as the product appears \"cool\" and \"futuristic\" in the context of the ad. The ad's creative concept and design may capture the attention of the target audience and generate interest in the product.\n",
    "Run Time: 3.995788097381592\n",
    "========================\n",
    "\n",
    "========================\n",
    "Ad: /kellogg/software/llama_cpp/code/ads/kawaii.png\n",
    "Response: \n",
    "USER:  \n",
    "You are thirsty young adult between age 25 and 30 taking a marketing survey. \n",
    "Can you describe if this soft drink ad appeals to you?\n",
    "\n",
    "ASSISTANT:\n",
    "The soft drink ad features a pink and white can with a cute cat and a small heart that says \"Coco Cola.\" A straw is sticking out of the can. The cat appears to be a popular emo symbol, which might appeal to young adults. The ad's design is visually appealing and playful, which could make the soft drink more attractive to the target audience. The use of a cute and quirky image can create a positive association with the product, potentially increasing its popularity and sales among the desired demographic.\n",
    "Run Time: 3.008307695388794\n",
    "========================\n",
    "========================\n",
    "Ad: /kellogg/software/llama_cpp/code/ads/cubs.png\n",
    "Response: \n",
    "USER:  \n",
    "You are thirsty young adult between age 25 and 30 taking a marketing survey. \n",
    "Can you describe if this soft drink ad appeals to you?\n",
    "\n",
    "ASSISTANT:\n",
    "The ad features a glass filled with a soft drink and a can of the same soft drink. The glass has ice in it, and the can has a straw. The ad also includes several people in the background, suggesting a social setting where people are enjoying the soft drink. The ad's visual appeal is enhanced by the presence of people, creating a sense of community and enjoyment associated with the soft drink. The combination of the glass with ice and the can with a straw presents the soft drink as a refreshing beverage that can be enjoyed in various settings, whether it's a casual gathering or a sports event. As a young adult, this ad might appeal to me because it portrays a lifestyle that I can relate to and shows the soft drink as a suitable drink for social occasions.\n",
    "Run Time: 4.399393796920776\n",
    "========================\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}