{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='purple'>__Introduction__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} <font color='purple'>__Objective__</font>\n",
    ":class: important\n",
    "The goals of this workshop are to look at best practices with regard to:\n",
    "\n",
    "- <font color='purple'>**Executing**</font> open source LLMs on Quest and on the Kellogg Linux Cluster (KLC)\n",
    "- <font color='purple'>**Adapting**</font> models by using fine-tuning to improve performance and accuracy\n",
    "- <font color='purple'>**Integrating**</font> external resources with models at run-time to update knowledge sources\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition}  <font color='purple'>__Project Lifecycle__</font>\n",
    "\n",
    "Every LLM project goes through at least some version of this lifecycle:\n",
    "\n",
    "```{figure} ./images/project-lifecycle-1.png\n",
    "---\n",
    "width: 900px\n",
    "name: gpt-dev-cycle1\n",
    "---\n",
    "```\n",
    "(Diagram taken from [DeepLearning.AI](https://www.deeplearning.ai/), provided under the Creative Commons License)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} <font color='purple'>__Define the Use Case__</font>\n",
    "\n",
    "One key to success is coming up with a well-defined use case that your LLM application will implement:\n",
    "\n",
    "```{figure} ./images/project-lifecycle-2.png\n",
    "---\n",
    "width: 900px\n",
    "name: gpt-dev-cycle2\n",
    "---\n",
    "```\n",
    "\n",
    "Your plan should specify:\n",
    "* What data will I be using to achieve my research goal?\n",
    "* How much data do I need?\n",
    "* How will I evaluate LLM output? \n",
    "* What counts as good enough?\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} <font color='purple'>__Select a Model__</font>\n",
    "\n",
    "There are many model choices avaialble. We can use leaderboards to choose the best one for our use case, and model hubs to download and run them locally.\n",
    "\n",
    "- Reproducibility\n",
    "- Cost\n",
    "- Data privacy\n",
    "- Flexibility to do fine-tuning\n",
    "\n",
    "```{figure} ./images/project-lifecycle-3.png\n",
    "---\n",
    "width: 900px\n",
    "name: gpt-dev-cycle3\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Models vs. Code\n",
    "\n",
    "\n",
    "```{figure} ./images/model-v-code.drawio.png\n",
    "---\n",
    "width: 900px\n",
    "name: model-v-code\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Model Hubs\n",
    "\n",
    "One widely used model hub is from [Hugging Face](https://huggingface.co/docs/hub/en/models-the-hub):\n",
    "\n",
    "```{figure} ./images/model-hub.png\n",
    "---\n",
    "width: 900px\n",
    "name: model-hub\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{card} Benchmarks and Leaderboards\n",
    "\n",
    "This is the [chatbot arena leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) as of 2024-03-04:\n",
    "\n",
    "```{figure} ./images/chatbot-leaderboard.png\n",
    "---\n",
    "width: 900px\n",
    "name: chatbot-leaderboard\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} <font color='purple'>__Adapt and Improve the Model__</font>\n",
    "\n",
    "While we should always start with crafting good prompts in order to achieve the best performance we can, it may sometimes be advantageous to adapt a model to improve its performance. Fine-tuning is one way to achieve this goal.\n",
    "\n",
    "```{figure} ./images/project-lifecycle-4.png\n",
    "---\n",
    "width: 900px\n",
    "name: gpt-dev-cycle4\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} <font color='purple'>__Integrate External Resources__</font>\n",
    "\n",
    "No model can \"know\" anything about events that have occurred after its training cutoff date. One way to overcome this obstacle is to integrate external resources, using tehcniques such as Retrieval Augmented Generation (RAG). RAG can result in better prompt completions and fewer \"hallucinations\".\n",
    "\n",
    "```{figure} ./images/project-lifecycle-5.png\n",
    "---\n",
    "width: 900px\n",
    "name: gpt-dev-cycle5\n",
    "---\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}